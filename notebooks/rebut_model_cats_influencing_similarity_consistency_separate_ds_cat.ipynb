{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb0c0e0cee960d5",
   "metadata": {},
   "source": [
    "## Notebook 4.5: *Which model categories influence relative similarity consistency?*\n",
    "This notebook creates figures for section 4.5. It generates the boxplots showing the distribution of correlation coefficients between dataset pairs for each model category (training objective, architecture, training data diversity, and size). Each plot is colored by model subcategories and sorted by median correlation. We compare these distributions against the baseline correlation coefficients of ungrouped models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1d0c8-c2ef-440c-85c3-8c18d12a2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from textwrap import wrap\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from itertools import product\n",
    "import json \n",
    "from pathlib import Path\n",
    "from constants import (\n",
    "    model_size_order,\n",
    "    fontsizes,\n",
    "    fontsizes_cols,\n",
    "    cat_color_mapping,\n",
    "    BASE_PATH_RESULTS,\n",
    "    ds_list_sim_file,\n",
    "    model_cat_mapping\n",
    ")\n",
    "from helper import save_or_show, pp_storing_path, load_all_datasetnames_n_info\n",
    "\n",
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed5976b0e4d4f5b",
   "metadata": {},
   "source": [
    "#### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1117c1-b686-4b0a-a8a4-74a2a389b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "ds_list, ds_info = load_all_datasetnames_n_info(ds_list_sim_file, verbose=False)\n",
    "\n",
    "# Experiment configuration\n",
    "corr_type = 'pearsonr'  # 'pearsonr', 'spearmanr'\n",
    "suffix = '_with_rsa'  # '', '_wo_mae', '_with_rsa', '_with_rsa_wo_mae_rotnet_jigsaw'\n",
    "exp_conf = f'{corr_type}{suffix}'\n",
    "\n",
    "# Path to correlation data\n",
    "data_path = BASE_PATH_RESULTS / f'aggregated/r_coeff_dist/with_cats_as_anchors/agg_{corr_type}_all_ds{suffix}.csv'\n",
    "print(data_path)\n",
    "assert data_path.exists(), f'Path does not exist: {data_path}. Aggregated correlation coefficients across all dataset pairs not found, please run aggregate_consistencies_for_model_set_pairs.ipynb first.'\n",
    "\n",
    "# Path to sim data\n",
    "sim_data_path = BASE_PATH_RESULTS / f'aggregated/model_sims/all_metric_ds_model_pair_similarity{suffix}.csv'\n",
    "assert sim_data_path.exists(), f\"Path does not exist: {sim_data_path}. Aggregated similarity data not found, please run aggregate_similarities_across_datasets.ipynb before.\"\n",
    "\n",
    "# Version\n",
    "version = 'arxiv'\n",
    "curr_fontsizes = fontsizes if version == 'arxiv' else fontsizes_cols\n",
    "curr_fontsizes = {k: v + 1 for k, v in curr_fontsizes.items()}\n",
    "\n",
    "# Storing path\n",
    "SAVE = True\n",
    "storing_path = pp_storing_path(Path('/home/space/diverse_priors/results_rebuttal') / 'plots' / 'exp_distr_for_dataset_cats' / exp_conf, SAVE)\n",
    "print(f\"{storing_path=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db38f9b75317de3",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2fc6abf38f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_coeff_data = pd.read_csv(data_path)\n",
    "print(r_coeff_data.shape)\n",
    "r_coeff_data = r_coeff_data[r_coeff_data['ds1'].isin(ds_list) & r_coeff_data['ds2'].isin(ds_list)].reset_index(\n",
    "    drop=True).copy()\n",
    "print(r_coeff_data.shape)\n",
    "r_coeff_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a7ab3-ebc7-4303-9352-6b9eb2ac6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_coeff_data['ds1_cat'] = r_coeff_data['ds1'].map(ds_info['domain'].to_dict())\n",
    "r_coeff_data['ds2_cat'] = r_coeff_data['ds2'].map(ds_info['domain'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62decd6a-92c8-441a-9dea-cf36a950f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_coeff_data['ds_cat_pair'] = r_coeff_data[['ds1_cat', 'ds2_cat']].apply(lambda x: tuple(sorted(x.tolist())), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad1bfc-485c-4cf3-832f-c574e8a33812",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_cats = r_coeff_data['Comparison category'].unique()\n",
    "if 'Objective' in curr_cats and 'Dataset diversity' in curr_cats:\n",
    "    r_coeff_data['Comparison category'] = r_coeff_data['Comparison category'].map({\n",
    "        'Architecture': 'Architecture',\n",
    "        'Dataset diversity': 'Training data',\n",
    "        'Objective': 'Training objective',\n",
    "        'Model size': 'Model size',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4423a15b9e2ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'cat_pair' not in r_coeff_data:\n",
    "    r_coeff_data['cat_pair'] = r_coeff_data[['anchor_cat', 'other_cat']].apply(\n",
    "        lambda x: tuple(sorted([x['anchor_cat'], x['other_cat']])), axis=1)\n",
    "elif isinstance(r_coeff_data['cat_pair'].iloc[0], str):\n",
    "    r_coeff_data['cat_pair'] = r_coeff_data['cat_pair'].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfcc1eb-3f83-419a-b1d2-759148c5faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sim_data = pd.read_csv(sim_data_path)\n",
    "all_sim_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca40fc8-a1f3-4ec6-9341-10fe433832fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sim_data['model_pair'] = all_sim_data[['Model 1', 'Model 2']].apply(\n",
    "    lambda x: tuple(sorted([x['Model 1'], x['Model 2']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9c89f-4159-4bc4-9f79-07b6720d0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sim_data = all_sim_data[all_sim_data['DS'].isin(ds_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f566c31-c33c-4305-9a39-3c2ebe83b504",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ds_cats = list(ds_info.loc[ds_list, 'domain'].unique())\n",
    "ds_cat_combinations = list(product(unique_ds_cats, unique_ds_cats))\n",
    "ds_cat_combinations = sorted(list(set([tuple(sorted(tup))for tup in ds_cat_combinations ])))\n",
    "ds_cat_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061940eb-f372-4f65-89ba-e62ebd00f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_per_cat = ds_info.loc[ds_list].reset_index(names=['ds_name']).groupby('domain')['ds_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a545e-cc99-436f-a6f0-d8a4215bda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_corr(x, y, corr_type):\n",
    "    \"\"\" Compute correlation between two arrays x and y using the specified correlation\"\"\"\n",
    "    if corr_type == 'pearsonr':\n",
    "        corr, _ = pearsonr(x, y, )\n",
    "    elif corr_type == 'spearmanr':\n",
    "        corr, _ = spearmanr(x, y, )\n",
    "    else:\n",
    "        raise ValueError('Unknown corr type')\n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_all_correlations(df, corr_type, col_data):\n",
    "    r_vals = []\n",
    "\n",
    "    for ds_cat1, ds_cat2 in ds_cat_combinations:\n",
    "        if ds_cat1 == ds_cat2:\n",
    "            curr_ds_tuple_list = combinations(list(ds_per_cat.loc[ds_cat1]), 2)\n",
    "        else:\n",
    "            curr_ds_tuple_list = product(list(ds_per_cat.loc[ds_cat1]), list(ds_per_cat.loc[ds_cat2]))\n",
    "\n",
    "        for ds1, ds2 in curr_ds_tuple_list:\n",
    "            ds1_subset = df[df['DS'] == ds1]\n",
    "            ds2_subset = df[df['DS'] == ds2]\n",
    "            r_vals.append({\n",
    "                'ds1': ds1,\n",
    "                'ds2': ds2,\n",
    "                'ds_cat_pair': json.dumps((ds_cat1, ds_cat2)),\n",
    "                'r coeff': compute_corr(ds1_subset[col_data].values, ds2_subset[col_data].values, corr_type)\n",
    "                })\n",
    "    return pd.DataFrame(r_vals)\n",
    "\n",
    "\n",
    "def get_sim_metric_dist_info(df):\n",
    "    \"\"\"Get distribution information of the correlation coefficients computed over all dataset pairs for each similarity metric when no model grouping in used\"\"\"\n",
    "    all_corrs = get_all_correlations(df, corr_type, 'Similarity value')\n",
    "    return all_corrs.groupby('ds_cat_pair')['r coeff'].describe()\n",
    "\n",
    "dist_info_no_cats = {}\n",
    "for sim_metric, data in all_sim_data.groupby('Similarity metric'):\n",
    "    dist_info_no_cats[sim_metric] = get_sim_metric_dist_info(data)\n",
    "    print(sim_metric)\n",
    "    display(dist_info_no_cats[sim_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3822f59334973d7",
   "metadata": {},
   "source": [
    "#### Plotting helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd70264-76de-41d4-9ad3-9bbbcc53496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple2string(tup_dat):\n",
    "    return f\"{tup_dat[0]}, {tup_dat[1]}\"\n",
    "\n",
    "\n",
    "def wrap_labels(ax, width, break_long_words=False):\n",
    "    x_ticks = ax.get_xticks()\n",
    "    labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    wrapped_labels = ['\\n'.join(wrap(label, width, break_long_words=break_long_words)) for label in labels]\n",
    "    ax.set_xticks(x_ticks, wrapped_labels, rotation=0, ha='center')\n",
    "\n",
    "\n",
    "def create_custom_legend(color_maps):\n",
    "    legend_patches = [mpatches.Patch(color=color, label=cat) for cat, color in color_maps.items()]\n",
    "\n",
    "    plt.legend(handles=legend_patches, ncols=len(legend_patches),\n",
    "               title=\"\", loc='center', bbox_to_anchor=(0.5, -0.25),\n",
    "               fontsize=curr_fontsizes['ticks'],\n",
    "               frameon=False\n",
    "               )\n",
    "\n",
    "\n",
    "def get_colored_tick_labels(label, method_colors):\n",
    "    methods = label.split(', ')\n",
    "    colored_label = [(method, method_colors.get(method, 'black')) for method in\n",
    "                     methods]  # Default color is 'black' if method not found\n",
    "    return colored_label\n",
    "\n",
    "\n",
    "def set_colored_labels(ax, method_colors, y_pos_init=- 0.05, y_height=-0.11):\n",
    "    x_ticks = ax.get_xticks()\n",
    "    labels = [label.get_text() for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels([])  # Remove existing tick labels\n",
    "\n",
    "    # Get the figure renderer for bounding box calculations\n",
    "    renderer = ax.figure.canvas.get_renderer()\n",
    "\n",
    "    # Store all text objects and their bounding boxes for each tick position\n",
    "    all_boxes = []  # List to store (text_obj, bbox) for each tick position\n",
    "\n",
    "    # First pass: Create all text objects and get their bounding boxes\n",
    "    for tick_idx, (x_tick, label) in enumerate(zip(x_ticks, labels)):\n",
    "        colored_methods = get_colored_tick_labels(label, method_colors)\n",
    "        x_pos = x_tick\n",
    "        y_pos = y_pos_init\n",
    "        tick_texts = []\n",
    "        for i, (method, color) in enumerate(colored_methods):\n",
    "            method = method.split(' DS')[0]\n",
    "\n",
    "            text = ax.text(\n",
    "                x_pos, y_pos, method,\n",
    "                color=color,\n",
    "                fontsize=curr_fontsizes['label'],\n",
    "                ha='center',\n",
    "                va='top',\n",
    "                transform=ax.get_xaxis_transform(),\n",
    "                rotation=0,\n",
    "            )\n",
    "\n",
    "            bbox = text.get_window_extent(renderer=renderer)\n",
    "            tick_texts.append((text, bbox))\n",
    "            y_pos += y_height\n",
    "\n",
    "        all_boxes.append(tick_texts)\n",
    "\n",
    "\n",
    "def get_dist_plot_for_cat(r_coeff_subdata, curr_all_ds_info, verbose=False):\n",
    "    # remove duplicates\n",
    "    print('R coeff data before duplicate removal: ', r_coeff_subdata.shape)\n",
    "    r_coeff_subdata_wo_dup = r_coeff_subdata[\n",
    "        ~r_coeff_subdata[['ds1', 'ds2', 'cat_pair', 'r coeff']].duplicated()].reset_index(drop=True)\n",
    "    print('R coeff data after duplicate removal: ', r_coeff_subdata_wo_dup.shape)\n",
    "\n",
    "    # Get color maps\n",
    "    sub_cats = list(np.unique(r_coeff_subdata_wo_dup[['anchor_cat', 'other_cat']].apply(np.unique, axis=0)))\n",
    "    if r_coeff_subdata_wo_dup['Comparison category'].unique()[0] == 'Model size':\n",
    "        sub_cats = model_size_order\n",
    "    color_maps = {cat: cat_color_mapping[cat] for cat in sub_cats}\n",
    "\n",
    "    # Get sorting order\n",
    "    sorting_order = r_coeff_subdata_wo_dup.groupby('cat_pair')['r coeff'].median().sort_values(\n",
    "        ascending=False).index.tolist()\n",
    "    colors = [(color_maps[cat1], color_maps[cat2]) for (cat1, cat2) in sorting_order]\n",
    "    sorting_order = [tuple2string(tup_data) for tup_data in sorting_order]\n",
    "\n",
    "    # Convert tuples to strings\n",
    "    r_coeff_subdata_wo_dup['cat_pair'] = r_coeff_subdata_wo_dup['cat_pair'].apply(tuple2string)\n",
    "\n",
    "    tmp = r_coeff_subdata_wo_dup.groupby('cat_pair')['r coeff'].describe().sort_values('mean')\n",
    "    tmp['Mean - std over 0.5'] = (tmp['mean'] - 2 * tmp['std']) > 0.5\n",
    "    if verbose:\n",
    "        display(tmp)\n",
    "\n",
    "    # Plot\n",
    "    add_inches = 2.5 if version == 'arxiv' else 3.5\n",
    "    plt.figure(figsize=(len(sorting_order) + add_inches, 4))\n",
    "    g = sns.boxplot(\n",
    "        r_coeff_subdata_wo_dup,\n",
    "        x='cat_pair',\n",
    "        y='r coeff',\n",
    "        order=sorting_order\n",
    "    )\n",
    "\n",
    "    ## infor of corr when not using any categories \n",
    "    g.axhline(curr_all_ds_info['50%'], c='grey', ls=':', alpha=0.5, zorder=-1)\n",
    "    g.axhspan(curr_all_ds_info['25%'], curr_all_ds_info['75%'], fc='lightgrey', alpha=0.5, zorder=-1)\n",
    "\n",
    "    ## color label \n",
    "    set_colored_labels(g, color_maps)\n",
    "    g.tick_params(axis='y', which='major', labelsize=curr_fontsizes['ticks'])\n",
    "\n",
    "    ## adapt color boxes \n",
    "    for patch, color in zip(g.patches, colors):\n",
    "        patch.set_facecolor('none')\n",
    "\n",
    "        vertices = patch.get_path().vertices\n",
    "\n",
    "        # Get box position and dimensions\n",
    "        x = vertices[0, 0]  # left x position\n",
    "        width = vertices[2, 0] - x  # width of the box\n",
    "        y_bottom = vertices[1, 1]  # bottom of the box\n",
    "        y_top = vertices[2, 1]  # top of the box\n",
    "        height = y_top - y_bottom  # height of the box\n",
    "\n",
    "        cmap = LinearSegmentedColormap.from_list('gradient', [color[0], color[1]])\n",
    "\n",
    "        gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "        g.imshow(gradient, aspect='auto', cmap=cmap,\n",
    "                 extent=(x, x + width, y_bottom, y_top), zorder=-1)\n",
    "    g.set_xlim(-1, len(colors))\n",
    "    ylim = (r_coeff_subdata_wo_dup['r coeff'].min() - 0.05, r_coeff_subdata_wo_dup['r coeff'].max() + 0.05)\n",
    "    g.set_ylim(ylim)\n",
    "    g.set_xlabel('')\n",
    "    g.set_ylabel('Correlation coefficient', fontsize=curr_fontsizes['label'])\n",
    "\n",
    "    return plt.gcf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f54e81efea4ee",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e2fcc-bce6-4f55-b7d7-28ea178ec907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_plot_for_cat_ax(ax, r_coeff_subdata, curr_all_ds_info, verbose=False, ylim=(-0.6, 1.05)):\n",
    "    # remove duplicates\n",
    "    r_coeff_subdata_wo_dup = r_coeff_subdata[\n",
    "        ~r_coeff_subdata[['ds1', 'ds2', 'cat_pair', 'r coeff']].duplicated()].reset_index(drop=True)\n",
    "\n",
    "    # Get color maps\n",
    "    sub_cats = list(np.unique(r_coeff_subdata_wo_dup[['anchor_cat', 'other_cat']].apply(np.unique, axis=0)))\n",
    "    if r_coeff_subdata_wo_dup['Comparison category'].unique()[0] == 'Model size':\n",
    "        sub_cats = model_size_order\n",
    "    color_maps = {cat: cat_color_mapping[cat] for cat in sub_cats}\n",
    "\n",
    "    # Get sorting order\n",
    "    sorting_order = r_coeff_subdata_wo_dup.groupby('cat_pair')['r coeff'].median().sort_values(\n",
    "        ascending=False).index.tolist()\n",
    "    colors = [(color_maps[cat1], color_maps[cat2]) for (cat1, cat2) in sorting_order]\n",
    "    sorting_order = [tuple2string(tup_data) for tup_data in sorting_order]\n",
    "\n",
    "    # Convert tuples to strings\n",
    "    r_coeff_subdata_wo_dup['cat_pair'] = r_coeff_subdata_wo_dup['cat_pair'].apply(tuple2string)\n",
    "\n",
    "    tmp = r_coeff_subdata_wo_dup.groupby('cat_pair')['r coeff'].describe().sort_values('mean')\n",
    "    tmp['Mean - std over 0.5'] = (tmp['mean'] - 2 * tmp['std']) > 0.5\n",
    "    if verbose:\n",
    "        display(tmp)\n",
    "\n",
    "    ax = sns.boxplot(\n",
    "        r_coeff_subdata_wo_dup,\n",
    "        x='cat_pair',\n",
    "        y='r coeff',\n",
    "        order=sorting_order,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ## infor of corr when not using any categories \n",
    "    ax.axhline(curr_all_ds_info['50%'], c='grey', ls=':', lw=3, alpha=0.75, zorder=-1)\n",
    "    ax.axhspan(curr_all_ds_info['25%'], curr_all_ds_info['75%'], fc='lightgrey', alpha=0.75, zorder=-1)\n",
    "\n",
    "    ## color label \n",
    "    set_colored_labels(ax, color_maps)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=curr_fontsizes['ticks'])\n",
    "\n",
    "    ## adapt color boxes \n",
    "    for patch, color in zip(ax.patches, colors):\n",
    "        patch.set_facecolor('none')\n",
    "\n",
    "        vertices = patch.get_path().vertices\n",
    "\n",
    "        # Get box position and dimensions\n",
    "        x = vertices[0, 0]  # left x position\n",
    "        width = vertices[2, 0] - x  # width of the box\n",
    "        y_bottom = vertices[1, 1]  # bottom of the box\n",
    "        y_top = vertices[2, 1]  # top of the box\n",
    "        height = y_top - y_bottom  # height of the box\n",
    "\n",
    "        cmap = LinearSegmentedColormap.from_list('gradient', [color[0], color[1]])\n",
    "\n",
    "        gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "        ax.imshow(gradient, aspect='auto', cmap=cmap,\n",
    "                  extent=(x, x + width, y_bottom, y_top), zorder=-1)\n",
    "\n",
    "    ax.set_xlim(-1, len(colors))\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xlim(-0.75, len(sorting_order) - 0.25)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Correlation coeff.', fontsize=curr_fontsizes['label'])\n",
    "\n",
    "\n",
    "def create_subplot_figure(subset_data, curr_all_ds_info):\n",
    "    # Create figure\n",
    "    add_inches = 0.5 if version == 'arxiv' else 2.5\n",
    "    fig = plt.figure(figsize=(10 + add_inches, 3.5 * 3))  # Adjust size as needed\n",
    "\n",
    "    min_r_coeff = subset_data['r coeff'].min()\n",
    "    max_r_coeff = subset_data['r coeff'].max()\n",
    "    offset = 0.05 * (max_r_coeff - min_r_coeff)\n",
    "    ylim = (min_r_coeff-offset, max_r_coeff+offset)\n",
    "\n",
    "    # Create GridSpec with custom width ratios for the first row (2:1 ratio)\n",
    "    gs = GridSpec(3, 2, figure=fig,\n",
    "                  width_ratios=[2, 1],  # A gets 2 parts, B gets 1 part\n",
    "                  height_ratios=[1, 1, 1])  # Adjust heights if needed\n",
    "\n",
    "    # First row: A (2/3 width) and B (1/3 width)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])  # First plot (reference)\n",
    "    ax2 = fig.add_subplot(gs[0, 1], sharey=ax1)  # Share y with first plot\n",
    "    ax3 = fig.add_subplot(gs[1, :], sharey=ax1)  # Share y with first plot\n",
    "    ax4 = fig.add_subplot(gs[2, :], sharey=ax1)  # Share y with first plot\n",
    "    axes = [ax1, ax2, ax3, ax4]\n",
    "    plt.setp(ax2.get_yticklabels(), visible=False)\n",
    "\n",
    "    for cat, ax in zip(model_cat_mapping.values(), axes):\n",
    "        group_data = subset_data[subset_data['Comparison category'] == cat]\n",
    "\n",
    "        get_dist_plot_for_cat_ax(ax, group_data, curr_all_ds_info, verbose=False, ylim=ylim)\n",
    "\n",
    "        ax.set_title(cat, fontsize=curr_fontsizes['title'])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602fa26-f6b8-41b6-b867-0be1fb2f974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for group_key, group_data in r_coeff_data.groupby(['Comparison category', 'Similarity metric', 'ds_cat_pair']):\n",
    "#     print(group_key)\n",
    "#     curr_all_ds_info = dist_info_no_cats[group_key[1]].loc[json.dumps(group_key[2]),:]\n",
    "#     print(curr_all_ds_info)\n",
    "#     fig = get_dist_plot_for_cat(group_data, curr_all_ds_info, False)\n",
    "\n",
    "#     curr_cat, curr_sim, ds_cat_pair = group_key\n",
    "#     curr_cat = curr_cat.replace(\" \", \"_\").lower()\n",
    "#     curr_sim = curr_sim.replace(\" \", \"_\").lower()\n",
    "\n",
    "#     ds_cat_pair = ds_cat_pair[0].replace(\" \", \"_\").lower() +\"_n_\"+ ds_cat_pair[1].replace(\" \", \"_\").lower()\n",
    "\n",
    "#     save_or_show(fig, storing_path / f'dist_r_coeff_cat_anchor_box_{curr_cat}_{curr_sim}_{ds_cat_pair}.pdf', SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f38d1f-d633-4c8a-afb2-75e2373b6e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for group_key, subset_data in r_coeff_data.groupby(['Similarity metric', 'ds_cat_pair']):\n",
    "    print(group_key)\n",
    "    curr_all_ds_info = dist_info_no_cats[group_key[0]].loc[json.dumps(group_key[1]),:]\n",
    "    fig = create_subplot_figure(subset_data, curr_all_ds_info)\n",
    "\n",
    "    curr_sim = group_key[0].replace(\" \", \"_\").lower()\n",
    "    ds_cat_pair = group_key[1][0].replace(\" \", \"_\").lower() +\"_n_\"+ group_key[1][1].replace(\" \", \"_\").lower()\n",
    "    save_or_show(fig, storing_path / f'dist_r_coeff_cat_anchor_box_all_cats_{curr_sim}_{ds_cat_pair}.pdf', SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623af31-c311-436f-932b-ff10012edcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

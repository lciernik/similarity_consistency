{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "968ebba7574575d5",
   "metadata": {},
   "source": [
    "## Notebook 4.6: *Do dataset categories influence relative similarity consistency?*\n",
    "\n",
    "This notebook creates figures for section 4.6. We visualize correlation coefficients between all dataset pairs, both grouped by training objectives and without grouping. This provides a comprehensive view of consistency patterns across different dataset categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3803fca6-5068-4b1c-900e-58e1afce3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from constants import (\n",
    "    BASE_PATH_RESULTS,\n",
    "    cat_name_mapping,\n",
    "    ds_list_sim_file,\n",
    "    fontsizes\n",
    ")\n",
    "from helper import (\n",
    "    load_all_datasetnames_n_info,\n",
    "    pp_storing_path,\n",
    "    save_or_show\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79935ce323351c2c",
   "metadata": {},
   "source": [
    "#### Global variables and data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea6ec7-0895-4896-a25a-c686022cbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset information\n",
    "ds_list, ds_info = load_all_datasetnames_n_info(ds_list_sim_file, verbose=False)\n",
    "\n",
    "# Version and plotting info\n",
    "version = '3_opt'\n",
    "curr_fontsizes = {k: v + 1 for k, v in fontsizes.items()}\n",
    "\n",
    "## Storing information \n",
    "corr_method = 'pearsonr'  # spearmanr, pearsonr\n",
    "SAVE = True\n",
    "storing_path = pp_storing_path(BASE_PATH_RESULTS / 'plots' / 'final' / version / 'sec_4_6_r_coeff_mats', SAVE)\n",
    "\n",
    "## Load data\n",
    "orig_sim_data_path = BASE_PATH_RESULTS / f'aggregated/model_sims/all_metric_ds_model_pair_similarity.csv'\n",
    "assert orig_sim_data_path.exists(), f\"Path does not exist: {orig_sim_data_path}. Aggregated similarity data not found, please run aggregate_similarities_across_datasets.ipynb before.\"\n",
    "orig_sim_data = pd.read_csv(orig_sim_data_path)\n",
    "\n",
    "## Process Objective column\n",
    "orig_sim_data['Objective pair'] = orig_sim_data['Objective pair'].apply(eval)\n",
    "\n",
    "combinations_objectives = [('all', 'all'),\n",
    "                           ('Self-Supervised', 'Self-Supervised'),\n",
    "                           ('Image-Text', 'Supervised'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5d480-2e75-49eb-b465-37e7ee4536ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.loc['wds_vtab_diabetic_retinopathy', 'name'] = \"Diabet. Retino.\"\n",
    "ds_info.loc['wds_voc2007', 'name'] = \"VOC 2007\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15407de8f60b96b",
   "metadata": {},
   "source": [
    "#### Helper funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73971aa-587b-4ab5-ac1f-78bdae993ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(mcat1, mcat2, sim_data, curr_suffix = None):\n",
    "    if len(mcat1) > 0 and len(mcat2) > 0:\n",
    "        sim_data_flat = sim_data[sim_data['Objective pair'].apply(lambda x: sorted(x) == sorted([mcat1, mcat2]))].copy()\n",
    "        if curr_suffix is not None:\n",
    "            curr_suffix = f\"_{cat_name_mapping[mcat1]}_{cat_name_mapping[mcat2]}\" + curr_suffix\n",
    "    else:\n",
    "        sim_data_flat = sim_data\n",
    "    return sim_data_flat, curr_suffix\n",
    "\n",
    "\n",
    "def get_ds_combs(df):\n",
    "    n_ds = df['DS'].nunique()\n",
    "    available_ds = sorted(list(set(df['DS'].unique()).intersection(ds_list)))\n",
    "    available_domains = sorted(ds_info['domain'].unique().tolist())\n",
    "    # available_ds = sorted(available_ds, key = lambda x: available_domains.index(ds_info.loc[x, 'domain']))\n",
    "    available_ds = sorted(available_ds, key=lambda x: (ds_info.loc[x, 'domain'], ds_info.loc[x, 'name']))\n",
    "    combs_DS = list(combinations(available_ds, 2))\n",
    "    corr_mat = pd.DataFrame(index=available_ds, columns=available_ds).astype('float')\n",
    "    return available_ds, available_domains, combs_DS, corr_mat\n",
    "\n",
    "\n",
    "def get_r_coeff(x, y, method='pearsonr'):\n",
    "    if method == 'pearsonr':\n",
    "        corr, _ = pearsonr(x, y)\n",
    "    elif method == 'spearmanr':\n",
    "        corr, _ = spearmanr(x, y)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "    return corr\n",
    "\n",
    "\n",
    "def get_two_ds_data(ds1, ds2, all_sims):\n",
    "    data_2_ds = all_sims[all_sims['DS'].isin([ds1, ds2])].copy()\n",
    "    data_2_ds['model_pair'] = data_2_ds['Model 1'] + \", \" + data_2_ds['Model 2']\n",
    "    ds_similarities = pd.pivot_table(\n",
    "        data_2_ds,\n",
    "        columns='DS',\n",
    "        index='model_pair',\n",
    "        values='Similarity value',\n",
    "    )\n",
    "    return ds_similarities\n",
    "\n",
    "\n",
    "def fill_corr_mat(df, combs_DS, corr_mat):\n",
    "    for ds1, ds2 in combs_DS:\n",
    "        ds_sims = get_two_ds_data(ds1, ds2, df)\n",
    "        corr = get_r_coeff(ds_sims.values[:, 0], ds_sims.values[:, 1], method=corr_method)\n",
    "        corr_mat.loc[ds1, ds2] = float(corr)\n",
    "        corr_mat.loc[ds2, ds1] = float(corr)\n",
    "\n",
    "    np.fill_diagonal(corr_mat.values, 1)\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "def rename_idx_cols(corr_mat, available_ds):\n",
    "    new_naming = [ds_info.loc[ds, 'name'] for ds in available_ds]\n",
    "    corr_mat.index = new_naming\n",
    "    corr_mat.columns = new_naming\n",
    "    return corr_mat\n",
    "\n",
    "\n",
    "def get_all_correlations(df, corr_type, col_data):\n",
    "    r_vals = []\n",
    "    for ds1, ds2 in combinations(ds_list, 2):\n",
    "        ds1_subset = df[df['DS'] == ds1]\n",
    "        ds2_subset = df[df['DS'] == ds2]\n",
    "        r_vals.append({\n",
    "            'ds1': ds1,\n",
    "            'ds2': ds2,\n",
    "            'r coeff': get_r_coeff(ds1_subset[col_data].values, ds2_subset[col_data].values, corr_type)\n",
    "\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(r_vals)\n",
    "\n",
    "\n",
    "def get_all_ds_corr_mat(sim_metric):\n",
    "    all_sim_data = pd.read_csv(orig_sim_data_path)\n",
    "    all_sim_data = all_sim_data[all_sim_data['DS'].isin(ds_list)]\n",
    "    sim_data = all_sim_data[all_sim_data['Similarity metric'] == sim_metric]\n",
    "    r_corrs = get_all_correlations(sim_data, corr_method, 'Similarity value')\n",
    "    corr_mat = pd.DataFrame(columns=ds_list, index=ds_list, dtype=float)\n",
    "\n",
    "    def add_entries(row):\n",
    "        corr_mat.loc[row['ds1'], row['ds2']] = row['r coeff']\n",
    "        corr_mat.loc[row['ds2'], row['ds1']] = row['r coeff']\n",
    "\n",
    "    r_corrs.apply(add_entries, axis=1)\n",
    "    np.fill_diagonal(corr_mat.values, 1)\n",
    "    new_index = ds_info.loc[corr_mat.index, :].sort_values(['domain', 'name']).index\n",
    "    corr_mat = corr_mat.loc[new_index, new_index]\n",
    "    corr_mat.index = ds_info.loc[corr_mat.index, 'name']\n",
    "    corr_mat.columns = ds_info.loc[corr_mat.columns, 'name']\n",
    "    return corr_mat, list(new_index), sorted(ds_info.loc[new_index, 'domain'].unique())\n",
    "\n",
    "\n",
    "def plot_heatmap_v2(ax, corr_mat, available_ds, available_domains, vmin=-0.44, vmax=1, set_title=True, cbar=False):\n",
    "    sns.heatmap(corr_mat, square=True, cmap='mako', cbar=cbar, vmin=vmin, vmax=vmax, ax=ax)\n",
    "\n",
    "    tmp = np.where(\n",
    "        ~(ds_info.loc[available_ds, 'domain'].iloc[:-1].values == ds_info.loc[available_ds, 'domain'].iloc[1:].values))[\n",
    "        0]\n",
    "    tmp += 1\n",
    "\n",
    "    for val in tmp:\n",
    "        ax.axhline(val, c='black', ls=\":\", lw=2)\n",
    "        ax.axvline(val, c='black', ls=\":\", lw=2)\n",
    "\n",
    "    ax.tick_params('y', labelsize=curr_fontsizes['label'])\n",
    "    ax.tick_params('x', pad=0.1, labelsize=curr_fontsizes['label'] - 1)\n",
    "    labels = ax.get_xticklabels()\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "    if set_title:\n",
    "        text_pos = [(5, -2.2), (13, -2.2), (17.75, -2.2), (21.75, -2.2)]\n",
    "    \n",
    "        ax.text(text_pos[0][0], text_pos[0][1], '\\n'.join(available_domains[0].split(' ')).replace('ain', '.'), ha='center',\n",
    "                va='top', fontsize=curr_fontsizes['title'], color='black')\n",
    "        ax.text(text_pos[1][0], text_pos[1][1], '\\n'.join(available_domains[1].split(' ')).replace('ain', '.'), ha='center',\n",
    "                va='top', fontsize=curr_fontsizes['title'], color='black')\n",
    "        ax.text(text_pos[2][0], text_pos[2][1], '-\\n'.join(textwrap.wrap(available_domains[2], width=7)), ha='center',\n",
    "                va='top', fontsize=curr_fontsizes['title'], color='black')\n",
    "        ax.text(text_pos[3][0], text_pos[3][1], '-\\n'.join(textwrap.wrap(available_domains[3], width=5)), ha='center',\n",
    "                va='top', fontsize=curr_fontsizes['title'], color='black')\n",
    "\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def setup_figure(m, size_fig=7, size_bar=0.25, wspace=0.05):\n",
    "    fig = plt.figure(figsize=(m * size_fig + size_bar, size_fig))\n",
    "    gs = GridSpec(1, m + 1, width_ratios=[size_fig] * m + [size_bar], wspace=wspace)\n",
    "\n",
    "    # Create axes with shared x and y\n",
    "    ax0 = fig.add_subplot(gs[0, 0])\n",
    "    axs = [ax0] + [fig.add_subplot(gs[0, i], sharey=ax0, sharex=ax0) for i in range(1, m)]\n",
    "    return fig, gs, axs\n",
    "\n",
    "\n",
    "def add_colorbar(gs, cmap='mako', vmin=-0.44, vmax=1):\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm.set_array([])\n",
    "    cax = fig.add_subplot(gs[0, -1])\n",
    "    plt.colorbar(sm, cax=cax)\n",
    "    cax.tick_params(labelsize=curr_fontsizes['label'])\n",
    "\n",
    "\n",
    "def update_suffix(suffix, mcat1, mcat2):\n",
    "    def pp_str(x):\n",
    "        return x.lower().replace(' ', '_')\n",
    "\n",
    "    if mcat1 == mcat2:\n",
    "        suffix += f\"_2_{pp_str(mcat1)}\"\n",
    "    else:\n",
    "        suffix += f\"_{pp_str(mcat1)}_n_{pp_str(mcat2)}\"\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac0bfa780f8a65",
   "metadata": {},
   "source": [
    "### Compute consistency matrices computed on different subsets of model pairs representational similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b160e5d-9333-45cf-93fe-001b54ded612",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(combinations_objectives)\n",
    "\n",
    "for sim_metric in ['CKA RBF 0.4', 'CKA linear']:\n",
    "    print(sim_metric)\n",
    "\n",
    "    sim_data = orig_sim_data[orig_sim_data['Similarity metric'] == sim_metric].reset_index().copy()\n",
    "\n",
    "    suffix = \"_\" + sim_metric.replace(\" \", \"_\").lower()\n",
    "\n",
    "    fig, gs, axs = setup_figure(m, size_fig=6.5, size_bar=0.25, wspace=0.05)\n",
    "\n",
    "    for i, (mcat1, mcat2) in enumerate(combinations_objectives):\n",
    "        ax = axs[i]\n",
    "        if mcat1 == 'all' and mcat2 == 'all':\n",
    "            corr_mat, available_ds, available_domains = get_all_ds_corr_mat(sim_metric)\n",
    "        else:\n",
    "            sim_data_flat, _ = filter_data(mcat1, mcat2, sim_data, suffix)\n",
    "            available_ds, available_domains, combs_DS, corr_mat = get_ds_combs(sim_data_flat)\n",
    "            corr_mat = fill_corr_mat(sim_data_flat, combs_DS, corr_mat)\n",
    "            corr_mat = rename_idx_cols(corr_mat, available_ds)\n",
    "\n",
    "        plot_heatmap_v2(ax, corr_mat, available_ds, available_domains)\n",
    "\n",
    "        if i > 0:\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "\n",
    "        suffix = update_suffix(suffix, mcat1, mcat2)\n",
    "\n",
    "    add_colorbar(gs, cmap='mako', vmin=-0.44, vmax=1)\n",
    "\n",
    "    save_or_show(plt.gcf(), storing_path / f'grouped_heatmap{suffix}.pdf', SAVE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b69d0-c6ca-4969-a714-b2ff855328a4",
   "metadata": {},
   "source": [
    "### NEW: Compute consistency matrices computed on different subsets of model pairs representational similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a49508-df58-4b50-b020-70a9e43d4fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_metric = 'CKA linear'\n",
    "\n",
    "sim_data = orig_sim_data[orig_sim_data['Similarity metric'] == sim_metric].reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa17be-a37d-4176-8b56-81f41e2832a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_data(mcat1, mcat2):\n",
    "    sim_data_flat, _ = filter_data(mcat1, mcat2, sim_data, None)\n",
    "    available_ds, available_domains, combs_DS, corr_mat = get_ds_combs(sim_data_flat)\n",
    "    corr_mat = fill_corr_mat(sim_data_flat, combs_DS, corr_mat)\n",
    "    corr_mat = rename_idx_cols(corr_mat, available_ds)\n",
    "    return corr_mat, available_ds, available_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29ebc4-5726-4e11-ba5a-9f7c0d786876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(12, 16))  # Increased height\n",
    "gs = gridspec.GridSpec(2, 2, width_ratios=[1, 1], height_ratios=[1.6, 1])  # Larger top section\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "cmap='mako'\n",
    "vmin=-0.44\n",
    "vmax=1\n",
    "\n",
    "corr_mat, available_ds, available_domains = get_all_ds_corr_mat(sim_metric)\n",
    "plot_heatmap_v2(ax1, corr_mat, available_ds, available_domains, cbar=True)\n",
    "ax1.figure.axes[-1].tick_params(labelsize=curr_fontsizes['label'])\n",
    "\n",
    "corr_mat, available_ds, available_domains = get_subset_data('Self-Supervised', 'Self-Supervised')\n",
    "plot_heatmap_v2(ax3, corr_mat, available_ds, available_domains, set_title=False)\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "ax3.set_xlabel('SSL', fontsize=curr_fontsizes['title'])\n",
    "\n",
    "corr_mat, available_ds, available_domains = get_subset_data('Image-Text', 'Supervised')\n",
    "plot_heatmap_v2(ax4, corr_mat, available_ds, available_domains, set_title=False)\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "ax4.set_xlabel('Img-Txt & Sup', fontsize=curr_fontsizes['title'])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.25, wspace=0.05)\n",
    "save_or_show(plt.gcf(), storing_path / f'grouped_heatmap_{corr_method}_one_big_two_small.pdf', SAVE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
